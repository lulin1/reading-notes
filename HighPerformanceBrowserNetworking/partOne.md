# chapter 1 延迟与带宽

本章主要介绍对所有网络通信都有决定性影响的两个方面：延迟和带宽

	• 延迟

	分组从信息源发送到目的地所需的时间。

	• 带宽

	逻辑或物理通信路径最大的吞吐量。

![1-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/1-1.jpg)

延迟是消息（message）或分组（packet）从起点到终点经历的时间。这个定义简单明了，但却掩盖了很多有用的信息。事实上，任何系统都有很多因素可能影响传送消息
的时间。

下面看看路由器这个负责在客户端和服务器之间转发消息的设备，会牵涉哪些影响延迟的因素。
	
 	• 传播延迟
  
	消息从发送端到接收端需要的时间，是信号传播距离和速度的函数
  
	• 传输延迟
  
	把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数
  
	• 处理延迟
  
	处理分组首部、检查位错误及确定分组目标所需的时间
  
	• 排队延迟
  
	到来的分组排队等待处理的时间
  

以上延迟的时间总和，就是客户端到服务器的总延迟时间。传播时间取决于距离和信号通过的媒介，另外传播速度通常不超过光速。而传输延迟由传输链路的速率决
定，与客户端到服务器的距离无关。举个例子，假设有一个 10 MB 的文件，分别通过两个链路传输，一个 1 Mbit/s，另一个 100 Mbit/s。在 1 Mbit/s 的链路上，需要花10 s，而在 100 Mbit/s 的链路上，只需 0.1 s。


# chapter 2 TCP的构成

因特网有两个核心协议：IP 和 TCP。

	IP，即 Internet Protocol（因特网协议），负责联网主机之间的路由选择和寻址；

	TCP，即 Transmission Control Protocol（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。

TCP/IP 也常被称为“因特网协议套件”（Internet Protocol Suite），是由 Vint Cerf 和 Bob Khan 在他们1974 的论文“A Protocol for Packet Network Intercommunication”（一种分组网络互通的协议）中首次提出来的。

## 2.1 三次握手

![2-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/2-1.jpg)

	• SYN
	
	客户端选择一个随机序列号 x，并发送一个 SYN 分组，其中可能还包括其他 TCP标志和选项。
	
	• SYN ACK
	
	服务器给 x 加 1，并选择自己的一个随机序列号 y，追加自己的标志和选项，然后返回响应。
	
	• ACK
	
	客户端给 x 和 y 加 1 并发送握手期间的最后一个 ACK 分组。
	
	
三次握手完成后，客户端与服务器之间就可以通信了。客户端可以在发送 ACK 分组之后立即发送数据，而服务器必须等接收到 ACK 分组之后才能发送数据。这个启动通信的过程适用于所有 TCP 连接，因此对所有使用 TCP 的应用具有非常大的性能影响，因为每次传输应用数据之前，都必须经历一次完整的往返。	

三次握手带来的延迟使得每创建一个新 TCP 连接都要付出很大代价。而这也决定了提高 TCP 应用性能的关键，在于想办法重用连接。

## 2.2　拥塞预防及控制

TCP 加入了很多机制，以便控制双向发送数据的速度，比如： 流量控制、　拥塞控制　和　拥塞预防机制。

### 2.2.1  流量控制

 流量控制是一种预防发送端过多向接收端发送数据的机制。否则，接收端可能因为忙碌、负载重或缓冲区既定而无法处理。为实现流量控制，TCP 连接的每一方都要通告（图 2-2）自己的接收窗口（rwnd），其中包含能够保存数据的缓冲区空间大小信息。
 
 ![2-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/2-2.jpg)
 
 第一次建立连接时，两端都会使用自身系统的默认设置来发送 rwnd。
 
 不管怎样，如果其中一端跟不上数据传输，那它可以向发送端通告一个较小的窗口。假如窗口为零，则意味着必须由应用层先清空缓冲区，才能再接收剩余数据。这个过程贯穿于每个 TCP 连接的整个生命周期：每个 ACK 分组都会携带相应的最新 rwnd值，以便两端动态调整数据流速，使之适应发送端和接收端的容量及处理能力。
 
 ### 2.2.2 慢启动
 
 	接收窗口大小（rwnd）
	
	拥塞窗口大小（cwnd）
	
首先，三次握手，而且在此期间双方各自通过 ACK 分组通告自己的接收窗口（rwnd）大小（图 2-2）。在发送完最后一次 ACK 分组后，就可以交换应用数据了。

新 TCP 连接传输的最大数据量取 rwnd 和 cwnd 中的最小值，而服务器实际上可以向客户端发送 4 个 TCP 段，然后就必须停下来等待确认。此后，每收到一个 ACK，慢启动算法就会告诉服务器可以将它的 cwnd 窗口增加 1 个 TCP 段。每次收到 ACK后，都可以多发送两个新的分组。TCP 连接的这个阶段通常被称为“指数增长”阶段（图2-3），因为客户端和服务器都在向两者之间网络路径的有效带宽迅速靠拢。

 ![2-3.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/2-3.jpg)

 为什么知道有个慢启动对我们构建浏览器应用这么重要呢?因为包括 HTTP 在内的很多应用层协议都运行在 TCP 之上,无论带宽多大,每个 TCP 连接都必须经过慢启动阶段。换句话说,我们不可能一上来就完全利用连接的最大带宽!相反,我们要从一个相对较小的拥塞窗口开始,每次往返都令其翻倍(指数式增长)。而达到某个目标吞吐量所需的时间,就是客户端与服务器之间的往返时间和初始拥塞窗口大小的函数(公式 2-1)。
 
 ![formula2-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/formula2-1.jpg)

 
要达到客户端与服务器之间 64 KB 的吞吐量,需要 4 次往返(图 2-4),几百 ms 的延迟!至于客户端与服务器之间实际的连接速率是不是在 Mbit/s 级别,丝毫不影响这个结果。这就是慢启动。

 ![2-4.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/2-4.jpg)
 
 为减少增长到拥塞窗口的时间,可以减少客户端与服务器之间的往返时间。比如,把服务器部署到地理上靠近客户端的地方。要么,就把初始拥塞窗口大小增加到RFC 9828 规定的 10 段。

慢启动导致客户端与服务器之间经过几百 ms 才能达到接近最大速度的问题,对于大型流式下载服务的影响倒不显著,因为慢启动的时间可以分摊到整个传输周期内消化掉。

可是,对于很多 HTTP 连接,特别是一些短暂、突发的连接而言,常常会出现还没有达到最大窗口请求就被终止的情况。换句话说,很多 Web 应用的性能经常受到服务器与客户端之间往返时间的制约。因为慢启动限制了可用的吞吐量,而这对于小文件传输非常不利。


### 2.2.3 拥塞预防

认识到 TCP 调节性能 主要依赖丢包反馈机制非常重要。换句话说,这不是一个假设命题,而是一个具体何时发生的命题。慢启动以保守的窗口初始化连接,随后的每次往返都会成倍提高传输的数据量,直到超过接收端的流量控制窗口,即系统配置的拥塞阈值(ssthresh)窗口,或者有分组丢失为止,此时拥塞预防算法介入。

拥塞预防算法把丢包作为网络拥塞的标志,即路径中某个连接或路由器已经拥堵了,以至于必须采取删包措施。因此,必须调整窗口大小,以避免造成更多的包丢失,从而保证网络畅通。

重置拥塞窗口后,拥塞预防机制按照自己的算法来增大窗口以尽量避免丢包。


## 2.3 带宽延迟积

TCP 内置的　拥塞控制　和　预防机制　对性能还有另一个重要影响:　发送端和接收端理想的窗口大小,一定会因往返时间及目标传输速率而变化。

无论发送端发送的数据还是接收端接收的数据超过了未确认的最大数据量,都必须停下来等待另一方 ACK 确认某些分组才能继续。要等待多长时间呢?取决于往返时间!
	
	BDP ( Bandwidth-delay product ,带宽延迟积)
	
	数据链路的容量与其端到端延迟的乘积。这个结果就是任意时刻处于在途未确认状态的最大数据量。


## 2.4 队首阻塞

TCP 在不可靠的信道上实现了可靠的网络传输。基本的分组错误检测与纠正、按序交付、丢包重发,以及保证网络最高效率的流量控制、拥塞控制和预防机制,让TCP 成为大多数网络应用中最常见的传输协议。

每个 TCP 分组都会带着一个唯一的序列号被发出,而所有分组必须按顺序传送到接收端(图 2-8 )。如果中途有一个分组没能到达接收端,那么后续分组必须保存在接收端的 TCP 缓冲区,等待丢失的分组重发并到达接收端。这一切都发生在 TCP 层,应用程序对 TCP 重发和缓冲区中排队的分组一无所知,必须等待分组全部到达才能访问数据。在此之前,应用程序只能在通过 套接字 读数据时感觉到延迟交付。这种效应称为 TCP 的队首(HOL,Head of Line)阻塞。

队首阻塞造成的延迟可以让我们的应用程序不用关心分组重排和重组,从而让代码保持简洁。然而,代码简洁也要付出代价,那就是分组到达时间会存在无法预知的 延迟变化。这个时间变化通常被称为抖动,也是影响应用程序性能的一个主要因素。

无需按序交付数据或能够处理分组丢失的应用程序,以及对延迟或抖动要求很高的应用程序,最好选择 UDP 等协议。虽然 TCP 很流行,但它并不是唯一的选择,而且在某些情况下也不是最佳的选择。特别是按序交付和可靠交付有时候并不必要,反而会导致额外的延迟,对性能造成负面影响。


## 2.5 针对TCP的优化建议

TCP 是一个自适应的、对所有网络节点一视同仁的、最大限制利用底层网络的协议。因此,优化 TCP 的最佳途径就是 调整它感知当前网络状况的方式,根据它之上或之下的抽象层的类型和需求来改变它的行为。

	尽管如此,而且每个算法和反馈机制的具体细节可能会继续发展,但核心原理以及它们的影响是不变的:
	
	• TCP 三次握手增加了整整一次往返时间;
	
	• TCP 慢启动将被应用到每个新连接;
	
	• TCP 流量及拥塞控制会影响所有连接的吞吐量;
	
	• TCP 的吞吐量由当前拥塞窗口大小控制。

尽管带宽不断增长,但延迟依旧受限于光速,而且已经限定在了其最大值的一个很小的常数因子之内。大多数情况下,TCP 的瓶颈都是 延迟,而非 带宽。

调优 TCP 性能可以让服务器和客户端之间达到最大吞吐量和最小延迟。

### 2.5.1  服务器配置调优

一句话,让你的服务器跟上时代是优化发送端和接收端 TCP 栈的首要措施。
	
### 2.5.2  应用程序行为调优

	• 再快也快不过什么也不用发送,能少发就少发。
	
	• 我们不能让数据传输得更快,但可以让它们传输的距离更短。
	
	• 重用 TCP 连接是提升性能的关键。
	
	
### 2.5.3  性能检查清单

	• 把服务器内核升级到最新版本(Linux:3.2+);
	
	• 确保 cwnd 大小为 10;
	
	• 禁用空闲后的慢启动;
	
	• 确保启动窗口缩放;
	
	• 减少传输冗余数据;
	
	• 压缩要传输的数据;
	
	• 把服务器放到离用户近的地方以减少往返时间;
	
	• 尽最大可能重用已经建立的 TCP 连接。
	

# chapter 3 UDP的构成

1980 年 8 月,紧随 TCP/IP 之后,UDP(User Datagram Protocol,用户数据报协议)被 John Postel 加入了核心网络协议套件 。当时,正值 TCP 和 IP 规范分立为两个单独的 RFC。这个时间点非常重要,稍后我们会看到,UDP 的主要功能和亮点并不在于它引入了什么特性,而在于它忽略的那些特性。

数据报(datagram)和分组(packet)是两个经常被人混用的词,实际上它们还是有区别的。分组可以用来指代任何格式化的数据块,而数据报则通常只用来描述那些通过不可靠的服务传输的分组,既不保证送达,也不发送失败通知。正因为如此,很多场合下人们都把 UDP 中 User(用户)的 U,改成 Unreliable(不可靠)的 U,于是 UDP 就成了“不可靠数据报协议”(Unreliable Datagram Protocol)。这也是为什么把 UDP 分组称为数据报更为恰当的原因。

HTTP 并未规定要使用 TCP,但现实中所有 HTTP 实现(以及构建于其上的所有服务)都使用 TCP。WebRTC 着眼于在浏览器中通过 UDP 实现原生的语音和视频实时通信,以及其他形式的 P2P(Peer-to-Peer,端到端)通信。正是因为 WebRTC 的出现,UDP 作为浏览器中重要传输机制的地位才得以突显,而且还有了浏览器 API！


## 3.1 无协议服务

要理解为什么 UDP 被人称作“无协议”,必须从作为 TCP 和 UDP 下一层的 IP 协议说起。

 ![3-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/3-1.jpg)
 
UDP 协议会用自己的分组结构(图 3-2)封装用户消息,它只增加了 4 个字段: 源端口、目标端口、分组长度和校验和。这样,当 IP 把分组送达目标主机时,该主机
能够拆开 UDP 分组,根据目标端口找到目标应用程序,然后再把消息发送过去。仅此而已。

 ![3-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/3-2.jpg)
 
事实上,UDP 数据报中的源端口和校验和字段都是可选的。IP 分组的首部也有校验和,应用程序可以忽略 UDP 校验和。也就是说,所有错误检测和错误纠正工作都可
以委托给上层的应用程序。说到底,UDP 仅仅是在 IP 层之上通过嵌入应用程序的源端口和目标端口,提供了一个“应用程序多路复用”机制。明白了这一点,就可以总结一下 UDP 的无服务是怎么回事了。

	• 不保证消息交付
		不确认,不重传,无超时。
	• 不保证交付顺序
		不设置包序号,不重排,不会发生队首阻塞。
	• 不跟踪连接状态
		不必建立连接或重启状态机。
	• 不需要拥塞控制
		不内置客户端或网络反馈机制。
		
UDP 数据报有明确的限制:数据报必须封装在 IP 分组中,应用程序必须读取完整的消息。换句话说,数据报不能分片。

UDP 是一个简单、无状态的协议,适合作为其他上层应用协议的辅助。


## 3.2   UDP 与网络地址转换器

IPv4 地址只有 32 位长,因而最多只能提供 42.9 亿个唯一 IP 地址。1994 年,作为解决 IPv4 地址即将耗尽的一个临时性方案,IP 网络地址转换(NAT,Network Address Translator) 规范出台了,这就是 RFC 1631。


### 3.2.1  连接状态超时

NAT 转换的问题(至少对于 UDP 而言)在于必须维护一份精确的路由表才能保证数据转发。NAT 设备依赖连接状态,而 UDP 没有状态。这种根本上的错配是很多UDP 数据报传输问题的总根源。况且,客户端前面有很多个 NAT 设备的情况也不鲜见,问题由此进一步恶化了。

UDP 呢,没有握手,没有连接终止,实际根本没有可监控的连接状态机。

更糟糕的是,NAT 设备还被赋予了删除转换记录的责任,但由于 UDP 没有连接终止确认环节,任何一端随时都可以停止传输数据报,而不必发送通告。为解决这个问题,UDP 路由记录会定时过期。定时多长?没有规定,完全取决于转换器的制造商、型号、版本和配置。因此,对于较长时间的 UDP 通信,有一个事实上的最佳做法,即引入一个双向 keep-alive 分组,周期性地重置传输路径上所有 NAT 设备中转换记录的计时器。

 ![3-4.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/3-4.jpg)
 
 
### 3.2.3   STUN、TURN 与 ICE


## 3.3  针对 UDP 的优化建议

UDP 是一个简单常用的协议,经常用于引导其他传输协议。事实上,UDP 的特色在于它所省略的那些功能:连接状态、握手、重发、重组、重排、拥塞控制、拥塞预防、流量控制,甚至可选的错误检测,统统没有。这个面向消息的最简单的传输层在提供灵活性的同时,也给实现者带来了麻烦。你的应用程序很可能需要从头实现上述几个或者大部分功能,而且每项功能都必须保证与网络中的其他主机和协议和谐共存。


# chapter 4 传输层安全(TLS)

SSL(Secure Sockets Layer,安全套接字层)协议最初是网景公司为了保障网上交易安全而开发的,该协议通过加密来保护客户个人资料,通过认证和完整性检查来
确保交易安全。为达到这个目标,SSL 协议在直接位于 TCP 上一层的应用层被实现(图 4-1)。SSL 不会影响上层协议(如 HTTP、电子邮件、即时通讯),但能够保证
上层协议的网络通信安全。

 ![4-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/4-1.jpg)

	IETF 后 来 在 标 准 化 SSL 协 议 时, 将 其 改 名 为 Transport Layer Security(TLS,传输层安全)。很多人会混用 TLS 和 SSL,但严格来讲它们并不相同,因为它们指代的协议版本不同。
	
	
SSL 2.0 是该协议第一个公开发布的版本,但由于存在很多安全缺陷很快就被 SSL3.0 取代。鉴于 SSL 协议是网景公司专有的,IETF 成立了一个小组负责标准化该协
议,后来就有了 RFC 2246,即 TLS 1.0,也就是 SSL 3.0 的升级版。

## 4.1  加密 、 身份验证与完整性

TLS 协议的目标是为在它之上运行的应用提供三个基本服务:加密、身份验证和数据完整性。从技术角度讲,并不是所有情况下都要同时使用这三个服务。比如,可
以接受证书但不验证其真实性,而前提是你非常清楚这样做有什么安全风险且有防范措施。实践中,安全的 Web 应用都会利用这三个服务。

	• 加密
	  混淆数据的机制
	• 身份验证
	  验证身份标识有效性的机制
	• 完整性
	  消息是否被篡改或伪造的机制

为了建立加密的安全数据通道,连接双方必须就加密数据的密钥套件和密钥协商一致 。TLS 协议规定了一套严密的握手程序用于交换这些信息,相关内容将在 4.2 节
“TLS 握手”中介绍。握手机制中设计最巧妙的地方,就是其使用的公钥密码系统(也称“非对称密钥加密”),这套系统可以让通信双方不必事先“认识”即可商定共享的安全密钥,而且协商过程还是通过非加密通道完成的。

 ![4-other-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/4-other-1.jpg)
 ![4-other-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/4-other-2.jpg)


## 4.2 TLS握手

 ![4-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/4-2.jpg)
 
 	• 0 ms:TLS 在可靠的传输层(TCP)之上运行,这意味着首先必须完成 TCP 的“三次握手”,即一次完整的往返。
	• 56 ms:TCP 连接建立之后,客户端再以纯文本形式发送一些规格说明,比如它所运行的 TLS 协议的版本、它所支持的加密套件列表,以及它支持或希望使用		的另外一些 TLS 选项。
	• 84 ms:然后,服务器取得 TLS 协议版本以备将来通信使用,从客户端提供的加密套件列表中选择一个,再附上自己的证书,将响应发送回客户端。作为可选	      项,服务器也可以发送一个请求,要求客户端提供证书以及其他 TLS 扩展参数。
	• 112 ms:假设两端经过协商确定了共同的版本和加密套件,客户端也高高兴兴地把自己的证书提供给了服务器。然后,客户端会生成一个新的对称密钥,用服务
	  器的公钥来加密,加密后发送给服务器,告诉服务器可以开始加密通信了。到目前为止,除了用服务器公钥加密的新对称密钥之外,所有数据都以明文形式发		  送。
	• 140 ms:最后,服务器解密出客户端发来的对称密钥,通过验证消息的 MAC 检测消息完整性,再返回给客户端一个加密的“Finished”消息。
	• 168 ms:客户端用它之前生成的对称密钥解密这条消息,验证 MAC,如果一切顺利,则建立信道并开始发送应用数据。


