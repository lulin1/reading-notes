# chapter 9 HTTP简史

## 9.1 HTTP 0.9: 只有一行的协议

简单总结一下 HTTP 0.9 的功能:

	• 客户端 / 服务器、请求 / 响应协议;
  
	• ASCII 协议,运行于 TCP/IP 链接之上;
  
	• 设计用来传输超文本文档(HTML);
  
	• 服务器与客户端之间的连接在每次请求之后都会关闭。


## 9.2 HTTP 1.0: 迅速发展及参考性 RFC

该协议的关键变化:

	• 请求可以由于多行首部字段构成;
  
	• 响应对象前面添加了一个响应状态行;
  
	• 响应对象也有自己的由换行符分隔的首部字段;
  
	• 响应对象不局限于超文本;
  
	• 服务器与客户端之间的连接在每次请求之后都会关闭。
	
HTTP 1.0 的优化策略非常简单,就一句话:升级到 HTTP 1.1。完了!


## 9.3 HTTP 1.1: 互联网标准

HTTP 1.1 标准厘清了之前版本中很多有歧义的地方,而且还加入了很多重要的性能优化: 持久连接、分块编码传输、字节范围请求、增强的缓存机制、传输编码及请求管道。

![9-other-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/9-other-1.jpg)

![9-other-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/9-other-2.jpg)

最明显的差别是这里发送了两次对象请求,一次请求 HTML 页面,一次请求图片,这两次请求都是通过一个连接完成的。这个连接是持久的,因而可以重用 TCP 连接对同一主机发送多次请求,从而实现更快的用户体验。

为终止持久连接,客户端的第二次请求通过 Connection 首部,向服务器明确发送了关闭令牌。类似地,服务器也可以在响应完成后,通知客户端自己想要关闭当前TCP 连接。从技术角度讲,不发送这个令牌,任何一端也可以终止 TCP 连接。但为
确保更好地重用连接,客户端和服务器都应该尽可能提供这个信息。

	HTTP 1.1 改变了 HTTP 协议的语义,默认使用持久连接。换句话说,除非明确告知(通过 Connection: close 首部),
	否则服务器默认会保持连接打开。
  
  
	不过,这个功能也反向移植到了 HTTP 1.0,可以通过 Connection: Keep-Alive 首部来启用。
	实际上,如果你使用的是 HTTP 1.1,从技术上说不需要 Connection: Keep-Alive 首部,但很多客户端还是选择加上它。


## 9.4 HTTP 2.0: 改进传输性能

HTTP 2.0 的主要目标是改进传输性能,实现低延迟和高吞吐量。



# chapter 10 web性能要点

在任何复杂的系统中,性能优化的很大一部分工作就是把不同层之间的交互过程分解开来,弄清楚每一层次交互的约束和限制。到目前为止,我们已经比较详细地分析了一些个别网络组件(不同的物理交付方式和传输协议)。现在,我们把目光转向更宏观的 Web 性能优化:

	• 延迟和带宽对 Web 性能的影响;
	
	• 传输协议(TCP)对 HTTP 的限制;
	
	• HTTP 协议自身的功能和缺陷;
	
	• Web 应用的发展趋势及性能需求;
	
	• 浏览器局限性和优化思路。


## 10.1  超文本 、 网页和 Web 应用

结果,页面加载时间,这个一直以来衡量 Web 性能的事实标准,作为一个性能基础也越来越显得不够了。我们不再是构建网页,而是在构建一个动态、交互的 Web 应用。除了测量每个资源及整个页面的加载时间(PLT),还要回答有关应用的如下几个问题:

	• 应用加载过程中的里程碑是什么?
	
	• 用户第一次交互的时机何在? 
	
	• 什么交互应该吸引用户参与?
	
	• 每个用户的参与及转化率如何?
	
	
性能好坏及优化策略成功与否,与你定义应用的特定基准和条件,并反复测试的效果直接相关。

![10-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-1.jpg)

![10-1-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-1-2.jpg)



## 10.2 剖析现代 Web 应用

![10-2.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-2.jpg)


### 10.2.1  速度 、 性能与用户期望

![table-10-1.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/table-10-1.jpg)

### 10.2.2  分析资源瀑布

首先,必须知道每一个 HTTP 请求都由很多独立的阶段构成(图 10-3):DNS 解析、TCP 连 接 握 手、TLS 协 商( 必 要 时 )、 发 送 HTTP 请 求, 然 后 下 载 内 容。

![10-4.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-4.jpg)


## 10.3  性能来源 : 计算 、 渲染和网络访问

Web 应用的执行主要涉及三个任务:取得资源、页面布局和渲染、JavaScript 执行。其中,渲染和脚本执行在一个线程上交错进行,不可能并发修改生成的 DOM。


### 10.3.1  更多带宽其实不 ( 太 ) 重要


### 10.3.2  延迟是性能瓶颈

![10-6.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-6.jpg)



## 10.4  人造和真实用户性能度量

宽泛地说,在受控度量环境下完成的任何测试都可称为人造测试。首先,本地构建过程运行性能套件,针对基础设施加载测试,或者针对一组分散在各地的监控服务器加载测试,这些服务器定时运行脚本并记录输出。这些测试中的任何一个都可能测试不同的基础设施(如应用服务器的吞吐量、数据库性能、DNS 时间,等等),并作为稳定的基准辅助检测性能衰退或聚焦于系统的某个特定组件。


只要配置得当,人造测试就可以提供一个受控且可重现的性能测试环境。而这个环境非常适合发现和修复性能问题,确保用户体验。提示:确定一个关键的性能指标,并为它们分别设定一个“预算额度”,纳入人造测试计划。一旦哪个指标超出“预算”,马上拉响警报!


上述这些方面,加之其他一些类似情况,意味着除了人造测试,我们必须通过真实用户度量(RUM,Real-User Measurement)来获取用户使用我们应用的真实性能数据,从而确保性能度量的有效性。有一个好消息,W3C Web Performance Working Group 通过引入 Navigation Timing API(图 10-7)为我们做真实用户测试提供了便利,这个 API 目前已得到很多现代桌面和移动浏览器的支持。

![10-7.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/10-7.jpg)

Navigation Timing 的真正好处是它提供了以前无法访问的数据,比如 DNS 和 TCP连接时间,而且精确度极高(微秒级时间戳)。要获得这些数据,可以在浏览器中访
问标准的 performance.timing 对象。实际上,收集这些数据的过程很简单:加载页面,从用户浏览器中取得相应的计时对象,然后将其传回分析服务器!通过观察这些数据,就可以知道用户使用我们应用时的真实性能,发现不同硬件和不同网络连接导致的差异。



## 10.5  针对浏览器的优化建议

可行的优化手段会因浏览器而异,但从核心优化策略来说,可以宽泛地分为两类。

	• 基于文档的优化
		熟悉网络协议,了解文档、CSS 和 JavaScript 解析管道,发现和优先安排关键网
		络资源,尽早分派请求并取得页面,使其尽快达到可交互的状态。主要方法是优
		先获取资源、提前解析等。
		
	• 推测性优化
		浏览器可以学习用户的导航模式,执行推测性优化,尝试预测用户的下一次操
		作。然后,预先解析 DNS、预先连接可能的目标。
		
		
好消息是,所有这些优化都由浏览器替我们自动完成,经常可以节省几百 ms 的网络延迟。既然如此,那理解这些优化背后的原理就至关重要了,这样才能利用浏览器的这些特性,提升应用性能。大多数浏览器都利用了如下四种技术。


	• 资源预取和排定优先次序
		文档、CSS 和 JavaScript 解析器可以与网络协议层沟通,声明每种资源的优先
		级:初始渲染必需的阻塞资源具有最高优先级,而低优先级的请求可能会被临时
		保存在队列中。
		
	• DNS 预解析
		对可能的域名进行提前解析,避免将来 HTTP 请求时的 DNS 延迟。预解析可以
		通过学习导航历史、用户的鼠标悬停,或其他页面信号来触发。
		
	• TCP 预连接
		DNS 解析之后,浏览器可以根据预测的 HTTP 请求,推测性地打开 TCP 连接。
		如果猜对的话,则可以节省一次完整的往返(TCP 握手)时间。
		
	• 页面预渲染
		某些浏览器可以让我们提示下一个可能的目标,从而在隐藏的标签页中预先渲染
		整个页面。这样,当用户真的触发导航时,就能立即切换过来。



# chapter 11 HTTP 1.X

改进 HTTP 的性能是 HTTP 1.1 工作组的一个重要目标,后来这个版本也引入了大量增强性能的重要特性,其中一些大家比较熟知的有:

	• 持久化连接以支持连接重用;
	
	• 分块传输编码以支持流式响应;
	
	• 请求管道以支持并行请求处理;
	
	• 字节服务以支持基于范围的资源请求; 
	
	• 改进的更好的缓存机制。


Steve Souder 的《高性能网站建设指南》中概括了 14 条规则,有一半针对网络优化:

	• 减少 DNS查询
		每次域名解析都需要一次网络往返,增加请求的延迟,在查询期间会阻塞请求。
		
	• 减少 HTTP请求
		任何请求都不如没有请求更快,因此要去掉页面上没有必要的资源。
		
	• 使用 CDN
		从地理上把数据放到接近客户端的地方,可以显著减少每次 TCP 连接的网络延迟,增加吞吐量。
		
	• 添加 Expires首部并配置ETag标签
		相关资源应该缓存,以避免重复请求每个页面中相同的资源。
		Expires 首部可用于指定缓存时间,在这个时间内可以直接从缓存取得资源,完全避免 HTTP 请求。
		ETag 及 Last-Modified 首部提供了一个与缓存相关的机制,相当于最后一次更新的指纹或时间戳。
	
	• Gzip 资源
		所有文本资源都应该使用 Gzip 压缩,然后再在客户端与服务器间传输。一般来说,Gzip 可以减少 60%~80% 的文件大小,
		也是一个相对简单(只要在服务器上配置一个选项),但优化效果较好的举措。
	
	• 避免 HTTP重定向
		HTTP 重定向极其耗时,特别是把客户端定向到一个完全不同的域名的情况下,还会导致额外的 DNS 查询、TCP 连接延迟,等等。



## 11.1  持久连接的优点

实际上,这时候最简单的优化就是重用底层的连接!添加对 HTTP 持久连接的支持,就可以避免第二次 TCP 连接时的三次握手、消除另一次 TCP 慢启动的往返,节约
整整一次网络延迟。


在我们两个请求的例子中,总共只节约了一次往返时间。但是,更常见的情况是一次 TCP 连接要发送 N 次 HTTP 请求,这时:

	• 没有持久连接,每次请求都会导致两次往返延迟;
	
	• 有持久连接,只有第一次请求会导致两次往返延迟,后续请求只会导致一次往返延迟。
	
	
	
## 11.2   HTTP 管道

![11-4.jpg](https://github.com/lulin1/reading-notes/blob/master/HighPerformanceBrowserNetworking/pics/11-4.jpg)


图 11-4 演示了如下几个方面:

	• HTML 和 CSS 请求同时到达,但先处理的是 HTML 请求;
	
	• 服务器并行处理两个请求,其中处理 HTML 用时 40 ms,处理 CSS 用时 20 ms;
	
	• CSS 请求先处理完成,但被缓冲起来以等候发送 HTML 响应;
	
	• 发送完 HTML 响应后,再发送服务器缓冲中的 CSS 响应。
	
即使客户端同时发送了两个请求,而且 CSS 资源先准备就绪,服务器也会先发送HTML 响应,然后再交付 CSS。这种情况通常被称作队首阻塞,并经常导致次优化交付:不能充分利用网络连接,造成服务器缓冲开销,最终导致无法预测的客户端延迟。假如第一个请求无限期挂起,或者要花很长时间才能处理完,怎么办呢?在HTTP 1.1 中,所有后续的请求都将被阻塞,等待它完成。



## 11.3  使用多个 TCP 连接

只要必须支持 HTTP 1.x 客户端,就不得不想办法应对多 TCP 流的问题。而这又会带来一个明显的问题:为什么浏览器要规定每个主机 6 个连接呢?恐怕有读者也猜
到了,这个数字是多方平衡的结果:这个数字越大,客户端和服务器的资源占用越多,但随之也会带来更高的请求并行能力。每个主机 6 个连接只不过是大家都觉得比较安全的一个数字。对某些站点而言,这个数字已经足够了,但对其他站点来说,可能还满足不了需求。


限制每个主机最多 6 个连接,可以让浏览器检测出无意(或有意)的 DoS(Denialof Service)攻击。如果没有这个限制,客户端有可能消耗掉服务器的所有资源。



## 11.4  域名分区

根据 HTTP Archive 的统计,目前平均每个页面都包含 90 多个独立的资源,如果这些资源都来自同一个主机,那么仍然会导致明显的排队等待(图 11-5)。实际上,
何必把自己只限制在一个主机上呢?我们不必只通过一个主机(例如 www.example.com) 提 供 所 有 资 源, 而 是 可 以 手 工 将 所 有 资 源 分 散 到 多 个 子 域 名:{shard1,shardn}.example.com 。由于主机名称不一样了,就可以突破浏览器的连接限制,实现更高的并行能力。域名分区使用得越多,并行能力就越强!

当然,天下没有免费的午餐,域名分区也不例外:每个新主机名都要求有一次额外的 DNS 查询,每多一个套接字都会多消耗两端的一些资源,而更糟糕的是,站点作者必须手工分离这些资源,并分别把它们托管到多个主机上。

实践中,域名分区经常会被滥用,导致几十个 TCP 流都得不到充分利用,其中很多永远也避免不了 TCP 慢启动,最坏的情况下还会降低性能。此外,如果使用的是HTTPS ,那么由于 TLS 握手导致的额外网络往返,会使得上述代价更高。此时,请注意如下几条:

	• 首先,把 TCP 利用好,参见 2.5 节“针对 TCP 的优化建议”;
	
	• 浏览器会自动为你打开 6 个连接;
	
	• 资源的数量、大小和响应时间都会影响最优的分区数目;
	
	• 客户端延迟和带宽会影响最优的分区数目;
	
	• 域名分区会因为额外的 DNS 查询和 TCP 慢启动而影响性能。


域名分区是一种合理但又不完美的优化手段。请大家一定先从最小分区数目(不分区)开始,然后逐个增加分区并度量分区后对应用的影响。



## 11.5  度量和控制协议开销

HTTP 0.9 当初就是一个简单的只有一行的 ASCII 请求,用于取得一个超文本文档,这样导致的开销是最小的。HTTP 1.0 增加了请求和响应首部,以便双方能够交换有关请求和响应的元信息。最终,HTTP 1.1 把这种格式变成了标准:服务器和客户端都可以轻松扩展首部,而且始终以纯文本形式发送,以保证与之前 HTTP版本的兼容。


今 天, 每 个 浏 览 器 发 起 的 HTTP 请 求, 都 会 携 带 额 外 500-800 字 节 的 HTTP 元 数据:用户代理字符串、很少改变的接收和传输首部、缓存指令,等等。有时候,500-800 字节都少说了,因为没有包含最大的一块:HTTP cookie。现代应用经常通过cookie 进行会话管理、记录个性选项或者完成分析。综合到一起,所有这些未经压缩的 HTTP 元数据经常会给每个 HTTP 请求增加几千字节的协议开销。



## 11.6  连接与拼合

最快的请求是不用请求。不管使用什么协议,也不管是什么类型的应用,减少请求次数总是最好的性能优化手段。可是,如果你无论如何也无法减少请求,那么对HTTP 1.x 而言,可以考虑把多个资源捆绑打包到一块,通过一次网络请求获取:

	• 连接
	  把多个 JavaScript 或 CSS 文件组合为一个文件。
		
	• 拼合
	  把多张图片组合为一个更大的复合的图片。
	
对 JavaScript 和 CSS 来说,只要保持一定的顺序,就可以做到把多个文件连接起来而不影响代码的行为和执行。类似地,多张图片可以组合为一个“图片精灵”,然后
使用 CSS 选择这张大图中的适当部分,显示在浏览器中。这两种技术都具备两方面的优点。

	• 减少协议开销
	  通过把文件组合成一个资源,可以消除与文件相关的协议开销。如前所述,每个文件很容易招致 KB 级未压缩数据的开销。
	
	• 应用层管道
	  说到传输的字节,这两种技术的效果都好像是启用了 HTTP 管道:来自多个响应的数据前后相继地连接在一起,消除了额外的网络延迟。
	  实际上,就是把管道提高了一层,置入了应用中。
	
连接和拼合技术都属于以内容为中心的应用层优化,它们通过减少网络往返开销,可以获得明显的性能提升。可是,实现这些技术也要求额外的处理、部署和编码(比如选择图片精灵中子图的 CSS 代码),因而也会给应用带来额外的复杂性。此外,把多个资源打包到一块,也可能给缓存带来负担,影响页面的执行速度。



## 11.7  嵌入资源

嵌 入 资 源 是 另 一 种 非 常 流 行 的 优 化 方 法, 把 资 源 嵌 入 文 档 可 以 减 少 请 求 的 次 数。 比 如,JavaScript 和 CSS 代 码, 通 过 适 当 的 script 和 style 块 可 以 直 接 放 在 页 面 中, 而 图 片 甚 至 音 频 或 PDF 文 件, 
都 可 以 通 过 数 据 URI( data:[mediatype][;base64],data )的方式嵌入到页面中:

	<img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAAAAACH5BAAAAAAALAAAAAABAAEAAAICTAEAOw==" alt="1x1 transparent (GIF) pixel" />



# chapter 12 HTTP 2.0

HTTP 2.0 的目的就是通过支持请求与响应的多路复用来减少延迟,通过压缩 HTTP首部字段将协议开销降至最低,同时增加对请求优先级和服务器端推送的支持。为达成这些目标,HTTP 2.0 还会给我们带来大量其他协议层面的辅助实现,比如新的流量控制、错误处理和更新机制。上述几种机制虽然不是全部,但却是最重要的,所有 Web 开发者都应该理解并在自己的应用中利用它们。

HTTP 2.0 修改了格式化数据(分帧)的方式,以及客户端与服务器间传输这些数据的方式。这两点统帅全局,通过新的组帧机制向我们的应用隐藏了所有复杂性。换句话说,所有原来的应用都可以不必修改而在新协议运行。这当然是好事。


## 12.1  历史及其与 SPDY 的渊源

SPDY 是谷歌开发的一个实验性协议,于 2009 年年中发布,其主要目标是通过解决HTTP 1.1 中广为人知的一些性能限制,来减少网页的加载延迟。大致上,这个项目
设定的目标如下:

	• 页面加载时间(PLT,Page Load Time)降低 50%;
	
	• 无需网站作者修改任何内容;
	
	• 把部署复杂性降至最低,无需变更网络基础设施;
	
	• 与开源社区合作开发这个新协议;
	
	• 收集真实性能数据,验证这个实验性协议是否有效。
	

## 12.2  走向 HTTP 2.0

SPDY 是 HTTP 2.0 的催化剂,但 SPDY 并非 HTTP 2.0。

之所以要递增一个大版本到 2.0 ,主要是因为它改变了客户端与服务器之间交换数据的方式。为实现宏伟的性能改进目标,HTTP 2.0 增加了新的二进制分帧数据层,而
这一层并不兼容之前的 HTTP 1.x 服务器及客户端——是谓 2.0。
